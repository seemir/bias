\documentclass[../thesis.tex]{subfiles}

\begin{document}

\chapter{Experiments}
\label{chap:exp}

\noindent In this chapter, we present the results of the experiments done in this thesis. The results are split into two sections. The first section presents the results from the cluster analysis and the second section that of the classification of clinical outcomes. For each of the sections we present an overview of the statistical learning problems that the algorithms are to solve. In this, we also present the assumptions and the evaluation criteria that are used to rank the algorithms and the final results. 

\section{Cluster Analysis}

\noindent In the cluster analysis, we try to see how well the various clustering algorithms perform in producing phenotypically distinct clinical patient groups with HFpEF and HFmrEF. We organize this section in the following way: we start out by looking at the full sample data set, i.e. \texttt{HFfullDataSet.Rdat}. After the pre-processing, we will run the principal components thought the clustering algorithms. The idea is to see how well the clustering algorithms perform in producing patient groups that are more unique compared to the physicians evaluation. Our measure of success is the number of unique baseline characteristics that are statistically significant using the Person $\chi^2$ test for categorical variables, ANOVA for normally distributed variables and Kruskal–Wallis test for non-normally distributed variables \citep{kruskal1952use}. Significance used is that of the conventional 5\% level. The implementation is done using the \texttt{multigrps}-function from the \texttt{CBCgrps}-package in \texttt{r} \citep{CBCgrps}. The algorithms are first going to be performed on the BI clustering HF problem, i.e. to see how unique the patient groups produced are given that the only HF subtypes in the dataset is HFmrEF and HFpEF. After which we will see how well the algorithms perform in producing new clusters within the already defined patient groups from the first round. We will do the same analysis on both the groups that have been defined by the physicians and the first round clustering results. The full process flow for the cluster analysis is illustrated in Figure (\ref{fig:process_flow_clustering}).

\begin{figure}
    \centering
    \input{doc/thesis/images/process_flow_clustering.tex}
    \caption[Process flow clustering of patient groups]{\textit{Process flow clustering of patient groups}}
    \label{fig:process_flow_clustering}
\end{figure}

\subsection{The BI Clustering HF Problem}
\label{subsec:bi_clust}

In the current clustering problem we assume that the dataset is only comprised of two clusters, i.e. HFmrEF and HFpEF. Accordingly, we allow the algorithms to determine the patients that best correspond to each cluster. We have plotted the results of the BI clustering problem in Figure (\ref{fig:bi_clust_results}). This plot can in many ways seem very misguiding as it only displays the results along the two first principal components. Still, the figure illustrates that even if you only cluster based on the first four principal components (27.32\% of variance explained), one can produce more unique phenotypi-     

\input{doc/thesis/tables/baseline_char_actual_full.tex}

\input{doc/thesis/tables/baseline_char_HCKM_full.tex}

\noindent cally distinct patient groups than the physicians. As we can see from table (\ref{tab:baseline_char_actual_hckm}), the  Hierarchical and K-Means clustering algorithms both give the highest number of significant baseline characteristics (7 for only the cont. variables in the table and 62 in total) compared with the actual clustering done by the physicians (4 for the cont. variables and 59 in total, see table \ref{tab:baseline_char_actual_full}). The EM algorithm produces overall the lowest number of significant baseline characteristics (5 for cont. variables and 54 in total). Both the Hierarchical and K-Means algorithm produce the same clustering configurations. The baseline characteristics in the clustering of the patient using the Hierarchical and K-Means clustering show that for the first clustering (HFpEF) the \texttt{LVEF} is on average 57.5\% and for the second clustering (HFmrEF) the \texttt{LVEF} is on average 45\%. These are very similar values as that which was done by the physicians. We can also see for other baseline characteristics such as \texttt{ntprobnp} the average is at 2327 ng/L for the HFpEF group which is significantly different than that of the HFmrEF group 3723.5 ng/L, also this is very similar to what the physicians concluded with. For characteristics that are significantly different in the clustering with Hierarchical and K-Means, but not found in the clustering done by the physicians one can include the following continuous variables: hemoglobin (\texttt{hb}), packed cell volume (\texttt{pcv}) and the ewave (\texttt{ewave}). This may suggest that both the cluste-    

\input{doc/thesis/tables/baseline_char_EM_full.tex}

\noindent ring algorithms, i.e. HC and KM can be used as appropriate tools for physicians. The results from the EM algorithm (Table \ref{tab:baseline_char_actual_em}) show that a lot of the similar baseline characteristics are not statistically significant. The LVEF (\texttt{lvef}) and NTproBNP (\texttt{ntprobnp}) is very similar to both the Hierarchical and K-means clustering, but other characteristics such as hemoglobin (\texttt{hb}) and the packed cell volume (\texttt{pcv}) are not. Throughout the analysis we have found that the EM algorithm does not a good job of clustering patient groups compared to the Hierarchical and K-Means clustering algorithms. This could be because of the assumption of multivariate normal distribution does not hold for this data set or the fact that there is a high presence of categorical variables in the data set.

\subsection{Analysis of Post-Diagnosis}

\noindent In this section we will investigate the clustering results discussed previously. We have place an assumption of whether the physicians diagnosis is representative given an objective of producing the most unique patient groups. The clustering problem in this section assumes that the diagnosis done by the physicians is sufficient in regards to this objective, i.e. the clustering based on the \textit{post-diagnosis} done by the physicians produces the  

\input{doc/thesis/tables/results_clustering_subtypes.tex}

\noindent most unique patient groups. We compare these results to a clustering without an assumption of post-diagnosis done by the physicians and see if there are any substantial differences in results. We will only use the first two principal components (14.64\% of variance explained) to cluster the patients. The evaluation criteria is the same as in the previous section. Accordingly, we can see from Table (\ref{tab:n_baseline}) that the Hierarchical and K-Means clustering algorithms produces the same number of significant baseline characteristics in half of the cases examined.  We can also see from Table (\ref{tab:n_baseline}) that all algorithms analyzed produce on average more statistically significant baseline characteristics with the post-diagnosis assumption compared to without. The EM algorithm produces overall the lowest number of significant baseline characteristics (in three cases). An exception is when the EM algorithm is clustering HFpEF with post-diagnosis.\\ 
\indent Starting out with the subtype HFpEF given the assumption of post-diagnosis, we can see from tables (\ref{tab:baseline_char_phy_p_hc}) and (\ref{tab:baseline_char_phy_p_km}) that cluster 2 (Hierarchical \& K-Means) seems to contain patients that have a higher average \texttt{age} (85.45) with a packed cell volume (\texttt{pcv}) that is on average 0.33 $\pm$ 0.05. This cluster is very similar to cluster 1 produced by the EM algorithm. The ntprobnp (\texttt{ntprobnp}) of cluster 3 (Hierarchical \& K-Means) is the lowest at 1417 ng/L which is also statistically significant. The average number of red blood cells, i.e. the mean corpusular volume (\texttt{mcv}) is at its lowest for cluster 1 (Hierarchical \& K-means) with an average of 87 femtolitres. The number of significant baseline characteristics produced by the Hierarchical clustering is 53 (8 cont. and 48 categorical) and for the K-Means its 49 (8 cont. and 41 categorical). The EM algorithm produces almost similar results for the subgroup HFpEF as the Hierarchical and K-Means algorithm (table \ref{tab:baseline_char_phy_p_em}). The second cluster produced by the EM algorithm is very similar to the third cluster produced by the Hierarchical and the K-Means algorithm. The ntprobnp (\texttt{ntprobnp}) for cluster one and two produced by the EM are very similar. Both are approximately 2750 ng/L. The third cluster produced by the EM algorithm has the lowest values for the ntprobnp (1525 nl/L). The total number of significant baseline characteristics for the EM algorithm is 56 (8 cont. and 48 categorical). \\ 
\indent When looking at the HFmrEF clustering based on post-diagnosis (tables \ref{tab:baseline_char_phy_mr_hc}, \ref{tab:baseline_char_phy_mr_km} and \ref{tab:baseline_char_phy_mr_em}), we can see that a somewhat different results shows up, i.e. there are on average less significantly different baseline characteristics in all clusters produced by the algorithms regardless of whether the assumption of post-diagnosis is intact. For cluster 3 (Hierarchical and K-Means), we find the lowest ntprobnp (\texttt{ntprobnp}) at 2898.5 ng/L with a packed cell volume of 0.38 $\pm$ 0.04. This cluster also contains the patients with the lowest length of stay (7 days). The length of stay (\texttt{LOS}) is also a uniquely statistical significant baseline characteristic that is only significant in the HFmrEF subgroup of patients for all algorithms studied. Cluster 3 also has the highest hemoglobin (\texttt{hb}) at 123.79 $\pm$ 12.89 g/100mL. The clustering results without the post-diagnosis assumption shows very different results. In general, Figure (\ref{fig:clust_results_without_post_p}) and (\ref{fig:clust_results_without_post_mr}) show that the assignment of clustering happens with very little similarities, i.e. the cluster numbering as well as the baseline characteristics vary more when the assumption of post-diagnosis is removed. Comparing the number of significant baseline characteristics between the HFmrEF groups both with and without the post-diagnosis assumption shows that the latter has on average fewer baseline characteristics, see table (\ref{tab:n_baseline}). The same goes for the HFpEF group, i.e. we have reasons to believe that assuming the physicians diagnosis is representative, one can get additional clustered patient groups with higher degree of homogeneity compared to when this assumption is not intact. We have also demonstrated that the ML algorithms can be very useful in producing patient groups that are more phenotypically unique given that the objective is to challenge the diagnosis of the physicians, see section (\ref{subsec:bi_clust}). Now that we have presented the results of the clustering analysis, we move on to the results of the classification of the clinical outcomes. The source code, relevant plots and tables can be found in the appendix (\ref{chap:data_desc}).

\vspace*{-0,5cm}\section{Classification}

\noindent In this section we will present the results of the classification analysis. As mentioned in ML the procedure (figure \ref{fig:ML_proc_thesis}), we run the imputed data set through the various classification algorithms and accordingly run a cross validation in order to estimate the accuracy of the various algorithms. The accuracy along with Cohen’s kappa are the two evaluation criteria we use to rank the algorithms in this section. The process flow for the mentioned classification section is illustrated in Figure (\ref{fig:process_flow_classification}). 

\begin{figure}
    \centering
    \input{doc/thesis/images/process_flow_classification.tex}
    \caption[Process flow classification of clinical outcomes]{\textit{Process flow classification of clinical outcomes}}
    \label{fig:process_flow_classification}
\end{figure}

\subsection{Mortality Classifier}

\noindent The statistical learning problem in this section is given by a two-class classification problem where mortality is the clinical outcome in question. Our objective is to see how well the algorithms mentioned in Figure (\ref{fig:ML_proc_thesis}) perform in predicting the probability of mortality. We will train the algorithms using $5$-fold cross validation and evaluate the results using the accuracy, i.e. the proportion of true results and the Cohen's kappa defined by:
\begin{align}
    \kappa \equiv \frac{p_0 - p_e}{1 - p_e}
\end{align}
where $p_0$ is the accuracy given by ${\mathit  {ACC}}=({\mathit  {TP}}+{\mathit  {TN}})/(P+N)$, and $p_e = 1 / N^2 \sum_{k} n_{k1}n_{k2}$, where $k$ is the number of categories / classes, $N$ the number of items and $n_{k1}$ the number of times rater $i$ predicted category $k$. $p_e$ is also referred to as the expected accuracy, i.e. what the accuracy that any \textit{random} classifier would be expected to achieve. Accordingly, Cohen's kappa is also regarded as the inter-rater agreement for qualitative (categorical) items, i.e. it is like classification accuracy, except that it is normalized at the baseline of random chance on a dataset. A possible interpretation of this statistics is given in by the following \citep{ashby1991practical}: less than 0.20 = Poor agreement, 0.20 to 0.40 = Fair agreement, 0.40 to 0.60 = Moderate agreement, 0.60 to 0.80 = Good agreement and 0.80 to 1 = Very good agreement. As mentioned earlier, the statistical learning problem is that of a Binary classification problem given by whether  re-admission / mortality occurred (\texttt{TRUE}) or not (\texttt{FALSE}), i.e. the expected accuracy is $p_e = 0.50$. The total number of patients with post-confirmed mortality in this data set is 115 (approx 36\% of the total number of patients, see table \ref{tab:outcomes_class}). In addition to the classifica-

\begin{figure}[h!]
    \centering
    \scalebox{.8}{\input{doc/thesis/images/classification_mortality.tex}}
    \caption[Bi-classification of mortality as clinical outcome]{\textit{Bi-classification of mortality as clinical outcome}}
    \label{fig:bi_class_mort}
\end{figure}

\noindent tion algorithms mentioned in Figure (\ref{fig:ML_proc_thesis}), we have also included an additional set of algorithms (Naive Baise \texttt{nb} and logistic regression \texttt{logr}) for further analysis. These algorithms were not discussed in further details in the previous chapter, but are very common in the literature. The results of the mortality classification is illustrated in Figure (\ref{fig:bi_class_mort}) and Table (\ref{tab:class_mortality}). In the table we notice that there are three algorithm that overall yield very decent results given the accuracy and the kappa. These are in order of importance: the random forest (\texttt{rf}), linear discriminant analysis (\texttt{lda}) and logistic regression (\texttt{logr}). As we can see the random forest (\texttt{rf}) \citep{ho1995random} produces the best overall accuracy and kappa. The mean accuracy of the random forest classifier is estimated at 72\% with a kappa at 23. The next classifier which compared to random forest also yields decent results is the linear discriminant analysis (\texttt{lda}). With the LDA the estimated prediction of the mortality in the HF patients is 66\% with a kappa of 14. The last algorithm is the logistic regression (\texttt{logr}) with a mean accuracy of 65\% and a kappa of 11. We need to emphasize that even though one gets a somewhat high accuracy, the kappa is often considered to be a more robust  

\input{doc/thesis/tables/classification_mortality.tex}

\noindent evaluation criteria compared to the accuracy. This is because it takes into account that the agreement between estimated classification and actual classification can occur by chance. As the kappa is very low for all the classifiers mentioned in table (\ref{tab:class_mortality}), we cannot say with certainty that the classification algorithms can systematically predict the mortality outcome. However, we have reasons to believe that the three algorithms (random forest, linear discriminant analysis and logistic regression) all show signs of being fair algorithms when it comes to predicting mortality in HF patients. This is not discouraging results as similar results are reported in the literature, see e.g. \cite{shah2014phenomapping} and \cite{panahiazar2015using}.

\subsection{Re-admission Classifier}

\noindent In this section, we examine the classification problem related to re-admission. We have defined the re-admission outcome as whether a given patient was re-admitted in some form during the one-year period. As we mentioned in section (\ref{sec:data}) this could be either within 30 days (patient group \texttt{V}) or any other way (patient groups \texttt{U}). The results of the re-admission classification 

\begin{figure}[h!]
    \centering
    \scalebox{.8}{\input{doc/thesis/images/classification_readmission.tex}}
    \caption[Bi-classification of re-admission as clinical outcome]{\textit{Bi-classification of re-admission as clinical outcome}}
    \label{fig:bi_class_read}
\end{figure}

\noindent are illustrated in Figure (\ref{fig:bi_class_read}) and Table (\ref{tab:class_readmission}). The results are very much different than what we found with the mortality classification. Surprisingly, three algorithms seem to distinguish themselves from the others, namely the random forest (\texttt{rf}), support vector machines (\texttt{svm}) and logistic regression (\texttt{logr}). Interestingly, all three of these algorithm score very high both in terms of accuracy and kappa. The algorithm with the most promising results is the random forest. It has an estimated mean prediction accuracy of 99.7\% with a kappa of 0.994. The random forest is found to be the most superior classification algorithm in both predicting mortality and re-admission. This is not uncommon as in the literature there are many studies that report of the random forest as being a very effective algorithm for classifying clinical outcomes, see e.g. \cite{austin2013using} and \cite{zolfaghar2013big}. The next algorithm that show potential in predicting re-admission is the support vector machines (\texttt{svm}) algorithm. It has an estimated mean accuracy of 99.5\% with a kappa of 0.987. We consider this to be interesting as in the previous section we found that the SVM was one of the lowest performing algorithms when it comes to predicting mortality. The last algorithm that show potential is that of the logistic regression (\texttt{logr}). The estimated mean accuracy for this algorithm was 99.2\% with a kappa of 0.981. In addition to having a very good accuracy and kappa, its worth mentioning that given is level of simplicity, one can argue that the  

\vspace*{-0,1cm}\input{doc/thesis/tables/classification_readmission.tex}

\noindent logistic regression algorithm is more preferable to more advanced classification algorithm. In both the cases that we have examined, we have found that the random forest and the logistic regression algorithm perform decently. Both algorithms are also very different in terms of their level of complexity. They are also very much used in the literature and is often a favourite among practitioners of medical statistical analysis, see e.g. \cite{austin2013using}, \cite{zolfaghar2013big}, \cite{shah2014phenomapping} and \cite{panahiazar2015using}. Accordingly, we have reasons to believe that both the random forest and the logistic regression are the two main algorithms that show the most potential in predicting both the mortality and re-admission of HF patients.

\section{Discussion}

\noindent The objective of this was two fold: (i) we attempted to give a though analysis of how well various clustering algorithms (Hierarchical, K-Means and Expectation-Maximization) perform in producing phenotypically distinct clinical patient groups (i.e. phenomapping) with HFpEF and HFmrEF. Our strategy for answering this research question has been to compare the level of dissimilarity between patient groups that are produced at two levels. Firstly, we looked at the Bi-clustering problem where we compared the patient groups produced by the algorithms with that of the physicians. We found that if one assumes that the clustering algorithm that produces the most significantly different baseline characteristics as being the optimal. Then we have reasons to believe that the Hierarchical and K-Means clustering algorithms show signs of being a tool that physicians can use to cross-check their assumptions and diagnosis in order to further improve the diagnosis of patients with the preserved and mid-range subtypes of HF. Overall these algorithms produce 62 significantly different baseline characteristics compared to 59 produced by the physians. Secondly, we looked at how well the clustering algorithms performed in producing "new" patient groups within both subtypes of HF. We analyzed this by attempting to re-cluster patient groups from both the subtypes produced by the physicians and the ML algorithms. 

\end{document}