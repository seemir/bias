\documentclass[../thesis.tex]{subfiles}

\begin{document}

\chapter{Experiments}
\label{chap:exp}

\noindent In this chapter, we present the results of the experiments done in this thesis. The results are split into two sections. The first section presents the results from the cluster analysis and the second section that of the classification of clinical outcomes. For each of the sections we present an overview of the statistical learning problems that the algorithms are to solve. In this, we also present the assumptions and the evaluation criteria that are used to rank the algorithms and the final results. 

\section{Cluster analysis}

\noindent In the cluster analysis, we try to see how well the various clustering algorithms perform in producing phenotypically distinct clinical patient groups with HFpEF and HFmrEF. We organize this section in the following way: we start out by looking at the full sample data set, i.e. \texttt{HFfullDataSet.Rdat}. After the pre-processing, we will run the principal components thought the clustering algorithms. The idea is to see how well the clustering algorithms perform in producing patient groups that are more homogeneous compared to the physicians evaluation. Our measure of success is the number of unique baseline characteristics that are statistically significant using the Person $\chi^2$ test for categorical variables, ANOVA for normally distributed variables and Kruskalâ€“Wallis test for non-normally distributed variables \citep{kruskal1952use}. All the tests are run using conventional levels of significance. The implementation is done using the \texttt{multigrps}-function from the \texttt{CBCgrps}-package in \texttt{r} \citep{CBCgrps}. The algorithms are performed on the binary clustering HF problem, i.e. to see how unique the patient groups produced are given that the only HF subtypes in the dataset is HFmrEF and HFpEF. This means that we assume a priori that there are only two clusters in the data set. After this we will see how well the algorithms perform in producing "new clusters" within the already defined patient groups from the first round. We will do the same analysis on both the groups that have been defined by the physicians and the "best" first round clustering algorithm. The full process flow for the cluster analysis is illustrated in Figure (\ref{fig:process_flow_clustering}).

\begin{figure}
    \centering
    \input{doc/thesis/images/process_flow_clustering.tex}
    \caption[Process flow clustering of patient groups]{\textit{Process flow clustering of patient groups}}
    \label{fig:process_flow_clustering}
\end{figure}

\subsection{The binary clustering HF problem}
\label{subsec:bi_clust}

The current clustering problem assumes that the dataset is only comprised of two clusters, i.e. HFmrEF and HFpEF. Accordingly, we allow the algorithms to determine the patients that best correspond to each cluster. We have plotted the results of the binary clustering problem in Figure (\ref{fig:bi_clust_results}). This plot can in many ways seem very misguiding as it only displays the results along the first two principal components. Still, the figure illustrates that even if we only cluster based on the first four principal components (27.32\% of variance explained), we can produce more distinct patient     

\input{doc/thesis/tables/baseline_char_actual_full.tex}

\input{doc/thesis/tables/baseline_char_HCKM_full.tex}

\noindent groups than the physicians. As we can see from Table (\ref{tab:baseline_char_actual_hckm}), the hierarchical and k-means clustering algorithms both give the highest number of significant baseline characteristics (7 continuous and 55 categorical variables) compared with the actual clustering done by the physicians (4 continuous and 55 categorical variables, see Table \ref{tab:baseline_char_actual_full}). The EM algorithm produces overall the lowest number of significant baseline characteristics (5 continuous and 49 categorical variables). Both the hierarchical and k-means algorithm produce the same clustering configurations. The baseline characteristics in the clustering of the patients using the hierarchical and k-means clustering show that for the HFpEF cluster the \texttt{LVEF} is on average 57.5\% and for the second cluster (HFmrEF) the \texttt{LVEF} is on average 45\%. These are very similar values to what the physicians produced. We can also see that for other baseline characteristics such as \texttt{ntprobnp} the average is at 2327 ng/L for the HFpEF group which is significantly different than that of the HFmrEF group 3723.5 ng/L. This is also very similar to what the physicians concluded with. For characteristics that are significantly different in the clustering with hierarchical and k-means, but not found in the clustering done by the physicians one can include the following continuous variables: hemoglobin (\texttt{hb}), packed cell volume (\texttt{pcv}) and the ewave (\texttt{ewave}). This may suggest that both the hierarchical and k-means clustering algorithms    

\input{doc/thesis/tables/baseline_char_EM_full.tex}

\noindent can be used as appropriate tools for physicians. The results from the EM algorithm (Table \ref{tab:baseline_char_actual_em}) show that many of the similar baseline characteristics are not statistically significant. The LVEF (\texttt{lvef}) and NTproBNP (\texttt{ntprobnp}) are very similar to both the hierarchical and k-means clustering, but other characteristics such as hemoglobin (\texttt{hb}) and the packed cell volume (\texttt{pcv}) are not. Throughout the analysis we have found that the EM algorithm does not perform as well in clustering patient groups as the hierarchical and k-means clustering algorithms. This could be because the assumption of multivariate normal distribution does not hold for this data set or the fact that there is a high presence of categorical variables in the data set.

\subsection{Analysis of post-diagnosis}

\noindent In this section we will investigate the clustering results discussed previously. We have placed an assumption of whether the physicians diagnosis is representative given an objective of producing the most unique patient groups. The clustering problem in this section assumes that the diagnosis done by the physicians is sufficient in regards to this objective, i.e. the clustering based on the \textit{post-diagnosis} done by the physicians produces the  

\input{doc/thesis/tables/results_clustering_subtypes.tex}

\noindent most unique patient groups. We compare these results to a clustering without an assumption of post-diagnosis done by the physicians and see if there are any substantial differences in results. We will only use the first two principal components (14.64\% of variance explained) to cluster the patients. The evaluation criteria are the same as in the previous section. The number of clusters for the k-means and EM algorithm recommended by the \texttt{NbClust()} \citep{nbclust} function in \texttt{r} was three, i.e. 13 of the 23 indices in the procedure recommended using $C = 3$ as the optimal number of clusters for both the HFmrEF and HFpEF data sets. We can see from Table (\ref{tab:n_baseline}) that the hierarchical and k-means clustering algorithms produces the same number of significant baseline characteristics in half of the cases examined.  We can also see from Table (\ref{tab:n_baseline}) that all algorithms analyzed produce on average more statistically significant baseline characteristics with the post-diagnosis assumption compared to without. The EM algorithm produces overall the lowest number of significant baseline characteristics (in three cases). An exception is when the EM algorithm is clustering HFpEF with post-diagnosis.\\ 
\indent Beginning with the subtype HFpEF given the assumption of post-diagnosis, we can see from tables (\ref{tab:baseline_char_phy_p_hc}) and (\ref{tab:baseline_char_phy_p_km}) that cluster 2 (hierarchical \& k-means) seems to contain patients that have a higher average \texttt{age} (85.45) with a packed cell volume (\texttt{pcv}) that is on average 0.33 $\pm$ 0.05. This cluster is very similar to cluster 1 produced by the EM algorithm. The ntprobnp (\texttt{ntprobnp}) of cluster 3 (hierarchical \& k-means) is the lowest at 1417 ng/L which is also statistically significant. The average number of red blood cells, i.e. the mean corpusular volume (\texttt{mcv}) is at its lowest for cluster 1 (hierarchical \& k-means) with an average of 87 femtolitres. The number of significant baseline characteristics produced by the hierarchical clustering is 53 (8 cont. and 48 categorical) and for the k-means its 49 (8 cont. and 41 categorical). The EM algorithm produces almost similar results for the subgroup HFpEF as the hierarchical and k-means algorithm (table \ref{tab:baseline_char_phy_p_em}). The second cluster produced by the EM algorithm is very similar to the third cluster produced by the hierarchical and the k-means algorithm. The ntprobnp (\texttt{ntprobnp}) for cluster one and two produced by the EM are very similar. Both are approximately 2750 ng/L. The third cluster produced by the EM algorithm has the lowest values for the ntprobnp (1525 nl/L). The total number of significant baseline characteristics for the EM algorithm is 56 (8 cont. and 48 categorical). \\ 
\indent When looking at the HFmrEF clustering based on post-diagnosis (tables \ref{tab:baseline_char_phy_mr_hc}, \ref{tab:baseline_char_phy_mr_km} and \ref{tab:baseline_char_phy_mr_em}), we can see somewhat different results, i.e. there are on average less significantly different baseline characteristics in all clusters produced by the algorithms regardless of whether the assumption of post-diagnosis is intact. For cluster 3 (hierarchical and k-means), we find the lowest ntprobnp (\texttt{ntprobnp}) at 2898.5 ng/L with a packed cell volume of 0.38 $\pm$ 0.04. This cluster also contains the patients with the lowest length of stay (7 days). The length of stay (\texttt{LOS}) is also a uniquely statistically significant baseline characteristic that is only significant in the HFmrEF subgroup of patients for all algorithms studied. Cluster 3 also has the highest hemoglobin (\texttt{hb}) at 123.79 $\pm$ 12.89 g/100mL. The clustering results without the post-diagnosis assumption show very different results. In general, Figure (\ref{fig:clust_results_without_post_p}) and (\ref{fig:clust_results_without_post_mr}) show that the assignment of clustering have with very few similarities, i.e. the cluster numbering as well as the baseline characteristics vary more when the assumption of post-diagnosis is removed. Comparing the number of significant baseline characteristics between the HFmrEF groups both with and without the post-diagnosis assumption shows that the latter has on average fewer baseline characteristics, see Table (\ref{tab:n_baseline}). The same goes for the HFpEF group, i.e. we have reasons to believe that assuming the physicians diagnosis is representative, one can get additional clustered patient groups with higher degree of homogeneity compared to when this assumption is not intact. We have also demonstrated that the ML algorithms can be very useful in producing patient groups that are more phenotypically unique given that the objective is to challenge the diagnosis of the physicians, see section (\ref{subsec:bi_clust}). Now that we have presented the results of the clustering analysis, we move on to the results of the classification of the clinical outcomes. The source code, relevant plots and tables can be found in the appendix (\ref{chap:data_desc}).

\vspace*{-0,5cm}\section{Classification}

\noindent In this section we will present the results of the classification analysis. As mentioned in the ML procedure (Figure \ref{fig:ML_proc_thesis}), we train the algorithms using the imputed data sets with all the principal components and accordingly run cross validation in order to estimate the accuracy of the various algorithms. The accuracy along with Cohenâ€™s kappa are the two evaluation criteria we use to rank the algorithms in this section. The process flow for the mentioned classification section is illustrated in Figure (\ref{fig:process_flow_classification}). 

\begin{figure}[!t]
    \centering
    \input{doc/thesis/images/process_flow_classification.tex}
    \caption[Process flow classification of clinical outcomes]{\textit{Process flow classification of clinical outcomes}}
    \label{fig:process_flow_classification}
\end{figure}

\subsection{Mortality classifier}

\noindent The statistical learning problem in this section is a two-class classification problem where mortality is the clinical outcome in question. Our objective is to see how well the algorithms mentioned in Figure (\ref{fig:ML_proc_thesis}) perform in predicting the probability of mortality. We will train the algorithms using PCA and $10$-fold cross validation and evaluate the results using the accuracy, i.e. the proportion of true results and Cohen's kappa defined by:

\begin{align}
    \kappa \equiv \frac{p_0 - p_e}{1 - p_e}
\end{align}

\noindent where $p_0$ is the accuracy given by ${\mathit  {ACC}}=({\mathit  {TP}}+{\mathit  {TN}})/(P+N)$, and $p_e = 1 / N^2 \sum_{k} n_{k1}n_{k2}$, where $k$ is the number of categories / classes, $N$ the number of items and $n_{k1}$ the number of times rater $i$ predicted category $k$. $p_e$ is also referred to as the expected accuracy, i.e. what the accuracy that any \textit{random} classifier would be expected to achieve. Accordingly, Cohen's kappa is also regarded as the inter-rater agreement for qualitative (categorical) items, i.e. it is similar to the classification accuracy, except that it is normalized at the baseline of random chance on a dataset. A possible interpretation of this    

\begin{figure}[h!]
    \centering
    \scalebox{.8}{\input{doc/thesis/images/classificationMortality.tex}}
    \caption[Binary classification results: mortality]{\textit{Binary classification results: mortality}}
    \label{fig:bi_class_mort}
\end{figure}

\newpage
\noindent statistics is given by the following \citep{ashby1991practical}: less than 0.20 = Poor agreement, 0.20 to 0.40 = Fair agreement, 0.40 to 0.60 = Moderate agreement, 0.60 to 0.80 = Good agreement and 0.80 to 1 = Very good agreement. As mentioned earlier, the statistical learning problem is a binary classification problem given by whether  readmission / mortality occurred (\texttt{TRUE}) or not (\texttt{FALSE}), i.e. the expected accuracy is $p_e = 0.50$. We use principal component analysis to address the problem of higher dimensional multi-correlated variables. Accordingly, in the process of training the algorithms we use all principal components from the training in the classification of the clinical outcomes. The total number of patients with post-confirmed mortality in this data set is 115 (approx 36\% of the total number of patients, see Table \ref{tab:outcomes_class}). The results of the mortality classification is illustrated in Figure (\ref{fig:bi_class_mort}) and Table (\ref{tab:class_mortality}). In the table we notice that there are three algorithms that overall yield very decent results given the accuracy and the kappa. These are in order of importance: linear discriminant analysis (\texttt{lda}), logistic regression (\texttt{logr}) and naive Bayes (\texttt{nb}). As we can see the LDA (\texttt{lda}) produces the best overall accuracy and kappa. The mean accuracy of the LDA classifier is estimated at 69.9\% with a kappa at 0.19. The next classifier which compared to LDA also yields decent results is the logistic regression (\texttt{logr}) with a

\input{doc/thesis/tables/classification_mortality.tex}
\newpage
\noindent mean accuracy of 69.6\% and a kappa of 12. The last algorithm is the naive Bayes (\texttt{nb}). With the naive Bayes the estimated mean prediction accuracy of mortality is 66.4\% with a kappa of 0.098. We need to emphasize that even though one gets a somewhat high accuracy, the kappa is often considered to be a more robust evaluation criterion compared to the accuracy. This is because it takes into account that the agreement between estimated classification and actual classification can occur by chance. As the kappa is very low for all the classifiers mentioned in table (\ref{tab:class_mortality}), we cannot say with certainty that the classification algorithms can systematically predict mortality. However, we have reasons to believe that the three algorithms (linear discriminant analysis, logistic regression and naive Bayes) all show signs of being fair algorithms when it comes to predicting mortality in HF patients. Similar results are reported in the literature, see e.g. \cite{shah2014phenomapping} and \cite{panahiazar2015using}.

\subsection{Readmission classifier}

\noindent In this section, we examine the classification problem related to readmission. We have defined the readmission outcome as whether a given patient was re-admitted in some form during the one-year follow-up period. As we mentioned in section (\ref{sec:data}) this could be either within 30 days (patient group \texttt{V}) or any other way (patient groups \texttt{U}). The results of the readmission classification is illustrated in Figure (\ref{fig:bi_class_read}) and Table (\ref{tab:class_readmission}). The results are very different from what we found with the mortality classification. Surprisingly, three algorithms seem to distinguish themselves from the others, namely the linear discriminant analysis (\texttt{lda}), support vector machines (\texttt{svm}) and  

\vspace*{0,25cm}\input{doc/thesis/tables/classification_readmission.tex}

\noindent logistic regression (\texttt{logr}). Interestingly, all three of these algorithm score very high both in terms of accuracy and kappa. The algorithm with the most promising results is the linear discriminant analysis. It has an estimated mean prediction accuracy of 99.7\% with a kappa of 0.993. The LDA is found to be the most superior classification algorithm in both predicting mortality and readmission. The next algorithm that show potential in predicting readmission is the support vector machines (\texttt{svm}) algorithm. It has an estimated mean accuracy of 99.5\% with a kappa of 0.987. We consider this to be interesting as in the previous section we found that the SVM was one of the lowest performing algorithms when it comes to predicting mortality. This might suggest that modelling readmission with a non-linear structure is more realistic than doing so with mortality. The last algorithm that show potential is that of the logistic regression (\texttt{logr}). The estimated mean accuracy for this algorithm was 98.7\% with a kappa of 0.968. In addition to having a very good accuracy and kappa, its worth mentioning that given its level of simplicity, one can argue that the logistic regression algorithm is preferable to more advanced classification algorithms. This is not uncommon as in the literature there are many studies that report of logistic regression being a very effective algorithm for classifying clinical outcomes, see e.g. \cite{austin2013using} and \cite{zolfaghar2013big}. In both the cases that we have examined, we have found that the linear discriminant analysis and the logistic regression algorithms perform decently. These algorithms are very different in terms of their level of complexity. They are also very much used in the literature and often favourites among practitioners of medical statistical analysis, see e.g. \cite{austin2013using}, \cite{zolfaghar2013big}, \cite{shah2014phenomapping} and \cite{panahiazar2015using}. Accordingly, we have reasons to believe that the linear discriminant analysis and the logistic regression are the two algorithms that show the most potential in predicting both the mortality and readmission of HF patients.

\begin{figure}[th!]
    \centering
    \scalebox{.8}{\input{doc/thesis/images/classificationReadmission.tex}}
    \caption[Binary classification results: readmission]{\textit{Binary classification results: readmission}}
    \label{fig:bi_class_read}
\end{figure}

\section{Discussion}

\noindent The objective of this thesis was two fold: (i) we attempted to give a though analysis of how well various clustering algorithms (hierarchical, k-means and expectation-maximization) perform in producing phenotypically distinct clinical patient groups (i.e. phenomapping) with HFpEF and HFmrEF. Our strategy for answering this research question has been to compare the level of dissimilarity between patient groups that are produced at two levels. Firstly, we looked at the binary clustering problem where we compared the patient groups produced by the algorithms with those produced by the physicians. We found that if one defines the optimal clustering as that which has the highest number of significantly different baseline characteristics, then we have reasons to believe that the hierarchical and k-means clustering algorithms show signs of being better at clustering patients with HF compared to the physicians. Overall these algorithms produce 62 significantly different baseline characteristics compared to 59 produced by the physicians. Secondly, we looked at how well the clustering algorithms performed in producing "new" patient groups within both subtypes of HF. We analyzed this by attempting to re-cluster patient groups from both subtypes (HFmrEF and HFpEF) produced by the physicians and the "best" ML algorithms. Re-clustering within the subtypes generated by the physicians (also called the 'post-diagnosis' assumption) seem to show the greatest potential as the average number of significantly different baseline characteristics is the highest for this clustering compared to when the assumption is removed. On average all algorithms produce approximately 53 (HFpEF) and 50 (HFmrEF) significantly different baseline characteristics when the post-diagnosis assumption is present compared to when its removed (46, HFpEF and 49, HFmrEF). However, if the objective is to use the results to find additional "new clusters", we cannot say with certainty that the choice of clustering algorithms or the clustering data used (whether it is with or without post-diagnosis) will systematically enhance the "uniqueness" of the patient groups. We need to emphasize that the results need to be treated with great caution as they are very sensitive to the number of principal components used, the imputation method and the sample size. Nevertheless, the hierarchical and k-means algorithms seems to have the potential to be used as tools by physicians to cross-check their assumptions and rational in order to further improve the diagnosis of patients with the preserved and mid-range subtypes of HF. Similar findings are also reported in the literature, see e.g. \cite{shah2014phenomapping}, \cite{ahmad2014clinical}, \cite{alonso2015exploring}, \cite{kao2015characterization}, \cite{ahmad2016clinical} and \cite{katz2017phenomapping}.\\
\indent In the second (ii) part of the thesis we attempted to evaluate the performance of various classification algorithms (k-nearest neighbour, logistic regression, linear discriminant analysis, support vector machines and random forest) in predicting mortality and readmission. The results suggest that linear discriminant analysis and logistic regression are good candidates for doing that. They both rank very high compared to the other algorithms evaluated. The LDA algorithm has an estimated accuracy of approximately 69.9\% for mortality and 99.7\% for readmission. The logistic regression had similar results with approximately 69.6\% accuracy for mortality and 98.7\% for readmission. The results seem promising, but we need to emphasize that these results also need to be treated with great causation. As we mentioned in section (\ref{sec:data}), the data set used in this thesis had 15\% missing values. This is an aspect about our study that should not be neglected. We addressed the problem of missing values by imputation with a bootstrapped EM algorithm \citep{honaker2011amelia}. Maximum likelihood methods such as this one are praised by many in the literature for its ability to impute missing values, even if the variables in question are mixed, see \cite{schafer1997analysis}, \cite{schafer1998multiple} and \cite{allison1999missing}. However, we cannot with certainty say that this is the most optimal method of treating the missing values in the data set. Similarly to the clustering results, we need to emphasize that the results of the classification are sensitive to a number of factors, such as the imputation method and sample size. Nevertheless, our findings seem to confirm the findings reported in the literature, see e.g. \cite{austin2012regression}, \cite{zolfaghar2013big}, \cite{shah2014phenomapping}, \cite{panahiazar2015using} and \cite{koulaouzidis2016telemonitoring}.\\
\indent For future analysis, we recommend broadening this study by evaluating more algorithms. This is especially the case for the clustering analysis. All the algorithms that we analyzed have assumed that all the patients belong to a cluster. This is a somewhat strong assumption as it could be the case that some patients lay in an area that is "too uncertain" to assign to either subtypes. It could be interesting to see how density-based algorithms such as DBSCAN \citep{ester1996density} would perform in producing phenotypically distinct patient groups. It could also be interesting to see how the classification results vary with the subtype of HF, i.e. is it reasonable to assume that some algorithm predicts mortality and readmission more accurately if one limits the data to one subtype of HF? These are all suggestions for future analysis that can broaden our understanding of the complex syndrome of heart failure. 

\end{document}