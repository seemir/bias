\documentclass[../thesis.tex]{subfiles}

\begin{document}

\chapter{Experiments}
\label{chap:exp}

\noindent In this chapter, we present the results of the experiments done in this thesis. The results are split into two sections. The first section presents the results from the cluster analysis and the second section that of the classification of clinical outcomes. For each of the sections we present an overview of the statistical learning problems that the algorithms are to solve. In this, we also present the assumptions and the evaluation criteria that are used to rank the algorithms and the final results. 

\section{Cluster Analysis}

\noindent In the cluster analysis, we try to see how well the various clustering algorithms perform in producing phenotypically distinct clinical patient groups with HFpEF and HFmrEF. We organize this section in the following way: we start out by looking at the full sample data set, i.e. \texttt{HFfullDataSet.Rdat}. After the pre-processing, we will run the principal components thought the clustering algorithms. The idea is to see how well the clustering algorithms perform in producing patient groups that are more unique compared to the physicians evaluation. Our measure of success is the number of unique baseline characteristics that are statistically significant using the Person $\chi^2$ test for categorical variables, ANOVA for normally distributed variables and Kruskalâ€“Wallis test for non-normally distributed variables \citep{kruskal1952use}. Significance used is that of the conventional 5\% level. The implementation is done using the \texttt{multigrps}-function from the \texttt{CBCgrps}-package in \texttt{r} \citep{CBCgrps}. The algorithms are first going to be performed on the binary clustering HF problem, i.e. to see how unique the patient groups produced are given that the only HF subtypes in the dataset is HFmrEF and HFpEF. This means that we assume a priori that there are only two clusters in the data set. After this we will see how well the algorithms perform in producing "new clusters" within the already defined patient groups from the first round. We will do the same analysis on both the groups that have been defined by the physicians and the first round clustering results. The full process flow for the cluster analysis is illustrated in Figure (\ref{fig:process_flow_clustering}).

\begin{figure}
    \centering
    \input{doc/thesis/images/process_flow_clustering.tex}
    \caption[Process flow clustering of patient groups]{\textit{Process flow clustering of patient groups}}
    \label{fig:process_flow_clustering}
\end{figure}

\subsection{The Binary Clustering HF Problem}
\label{subsec:bi_clust}

The current clustering problem assumes that the dataset is only comprised of two clusters, i.e. HFmrEF and HFpEF. Accordingly, we allow the algorithms to determine the patients that best correspond to each cluster. We have plotted the results of the binary clustering problem in Figure (\ref{fig:bi_clust_results}). This plot can in many ways seem very misguiding as it only displays the results along the first two principal components. Still, the figure illustrates that even if one only cluster based on the first four principal components (27.32\% of variance explained), one can produce more distinct patient     

\input{doc/thesis/tables/baseline_char_actual_full.tex}

\input{doc/thesis/tables/baseline_char_HCKM_full.tex}

\noindent groups than the physicians. As we can see from Table (\ref{tab:baseline_char_actual_hckm}), the hierarchical and k-means clustering algorithms both give the highest number of significant baseline characteristics (7 continuous and 55 categorical variables) compared with the actual clustering done by the physicians (4 continuous and 55 categorical variables, see table \ref{tab:baseline_char_actual_full}). The EM algorithm produces overall the lowest number of significant baseline characteristics (5 continuous and 49 categorical variables). Both the hierarchical and k-means algorithm produce the same clustering configurations. The baseline characteristics in the clustering of the patient using the hierarchical and k-means clustering show that for the HFpEF cluster the \texttt{LVEF} is on average 57.5\% and for the second clustering (HFmrEF) the \texttt{LVEF} is on average 45\%. These are very similar values to what the physians produced. We can also see that for other baseline characteristics such as \texttt{ntprobnp} the average is at 2327 ng/L for the HFpEF group which is significantly different than that of the HFmrEF group 3723.5 ng/L. This is also very similar to what the physicians concluded with. For characteristics that are significantly different in the clustering with hierarchical and k-means, but not found in the clustering done by the physicians one can include the following continuous variables: hemoglobin (\texttt{hb}), packed cell volume (\texttt{pcv}) and the ewave (\texttt{ewave}). This may suggest that both the hierarchical and k-means clustering algorithms    

\input{doc/thesis/tables/baseline_char_EM_full.tex}

\noindent can be used as appropriate tools for physicians. The results from the EM algorithm (Table \ref{tab:baseline_char_actual_em}) show that a lot of the similar baseline characteristics are not statistically significant. The LVEF (\texttt{lvef}) and NTproBNP (\texttt{ntprobnp}) is very similar to both the hierarchical and k-means clustering, but other characteristics such as hemoglobin (\texttt{hb}) and the packed cell volume (\texttt{pcv}) are not. Throughout the analysis we have found that the EM algorithm does not a good job of clustering patient groups compared to the hierarchical and k-means clustering algorithms. This could be because of the assumption of multivariate normal distribution does not hold for this data set or the fact that there is a high presence of categorical variables in the data set.

\subsection{Analysis of Post-Diagnosis}

\noindent In this section we will investigate the clustering results discussed previously. We have place an assumption of whether the physicians diagnosis is representative given an objective of producing the most unique patient groups. The clustering problem in this section assumes that the diagnosis done by the physicians is sufficient in regards to this objective, i.e. the clustering based on the \textit{post-diagnosis} done by the physicians produces the  

\input{doc/thesis/tables/results_clustering_subtypes.tex}

\noindent most unique patient groups. We compare these results to a clustering without an assumption of post-diagnosis done by the physicians and see if there are any substantial differences in results. We will only use the first two principal components (14.64\% of variance explained) to cluster the patients. The evaluation criteria is the same as in the previous section. The number of clusters for the k-means and EM algorithm recommended by the \texttt{NbClust()} \citep{nbclust} function in \texttt{r} was three, i.e. 13 of the 23 indices in the procedure recommended using $C = 3$ as the optimal number of clusters for both the HFmrEF and HFpEF data sets. We can see from Table (\ref{tab:n_baseline}) that the hierarchical and k-means clustering algorithms produces the same number of significant baseline characteristics in half of the cases examined.  We can also see from Table (\ref{tab:n_baseline}) that all algorithms analyzed produce on average more statistically significant baseline characteristics with the post-diagnosis assumption compared to without. The EM algorithm produces overall the lowest number of significant baseline characteristics (in three cases). An exception is when the EM algorithm is clustering HFpEF with post-diagnosis.\\ 
\indent Beginning with the subtype HFpEF given the assumption of post-diagnosis, we can see from tables (\ref{tab:baseline_char_phy_p_hc}) and (\ref{tab:baseline_char_phy_p_km}) that cluster 2 (hierarchical \& k-means) seems to contain patients that have a higher average \texttt{age} (85.45) with a packed cell volume (\texttt{pcv}) that is on average 0.33 $\pm$ 0.05. This cluster is very similar to cluster 1 produced by the EM algorithm. The ntprobnp (\texttt{ntprobnp}) of cluster 3 (hierarchical \& k-means) is the lowest at 1417 ng/L which is also statistically significant. The average number of red blood cells, i.e. the mean corpusular volume (\texttt{mcv}) is at its lowest for cluster 1 (hierarchical \& k-means) with an average of 87 femtolitres. The number of significant baseline characteristics produced by the Hierarchical clustering is 53 (8 cont. and 48 categorical) and for the k-means its 49 (8 cont. and 41 categorical). The EM algorithm produces almost similar results for the subgroup HFpEF as the hierarchical and k-means algorithm (table \ref{tab:baseline_char_phy_p_em}). The second cluster produced by the EM algorithm is very similar to the third cluster produced by the hierarchical and the k-means algorithm. The ntprobnp (\texttt{ntprobnp}) for cluster one and two produced by the EM are very similar. Both are approximately 2750 ng/L. The third cluster produced by the EM algorithm has the lowest values for the ntprobnp (1525 nl/L). The total number of significant baseline characteristics for the EM algorithm is 56 (8 cont. and 48 categorical). \\ 
\indent When looking at the HFmrEF clustering based on post-diagnosis (tables \ref{tab:baseline_char_phy_mr_hc}, \ref{tab:baseline_char_phy_mr_km} and \ref{tab:baseline_char_phy_mr_em}), we can see that a somewhat different results shows up, i.e. there are on average less significantly different baseline characteristics in all clusters produced by the algorithms regardless of whether the assumption of post-diagnosis is intact. For cluster 3 (hierarchical and k-means), we find the lowest ntprobnp (\texttt{ntprobnp}) at 2898.5 ng/L with a packed cell volume of 0.38 $\pm$ 0.04. This cluster also contains the patients with the lowest length of stay (7 days). The length of stay (\texttt{LOS}) is also a uniquely statistical significant baseline characteristic that is only significant in the HFmrEF subgroup of patients for all algorithms studied. Cluster 3 also has the highest hemoglobin (\texttt{hb}) at 123.79 $\pm$ 12.89 g/100mL. The clustering results without the post-diagnosis assumption shows very different results. In general, Figure (\ref{fig:clust_results_without_post_p}) and (\ref{fig:clust_results_without_post_mr}) show that the assignment of clustering happens with very little similarities, i.e. the cluster numbering as well as the baseline characteristics vary more when the assumption of post-diagnosis is removed. Comparing the number of significant baseline characteristics between the HFmrEF groups both with and without the post-diagnosis assumption shows that the latter has on average fewer baseline characteristics, see table (\ref{tab:n_baseline}). The same goes for the HFpEF group, i.e. we have reasons to believe that assuming the physicians diagnosis is representative, one can get additional clustered patient groups with higher degree of homogeneity compared to when this assumption is not intact. We have also demonstrated that the ML algorithms can be very useful in producing patient groups that are more phenotypically unique given that the objective is to challenge the diagnosis of the physicians, see section (\ref{subsec:bi_clust}). Now that we have presented the results of the clustering analysis, we move on to the results of the classification of the clinical outcomes. The source code, relevant plots and tables can be found in the appendix (\ref{chap:data_desc}).

\vspace*{-0,5cm}\section{Classification}

\noindent In this section we will present the results of the classification analysis. As mentioned in the ML procedure (figure \ref{fig:ML_proc_thesis}), we run the imputed data set through the various classification algorithms and accordingly run a cross validation in order to estimate the accuracy of the various algorithms. The accuracy along with Cohenâ€™s kappa are the two evaluation criteria we use to rank the algorithms in this section. The process flow for the mentioned classification section is illustrated in Figure (\ref{fig:process_flow_classification}). 

\begin{figure}[!t]
    \centering
    \input{doc/thesis/images/process_flow_classification.tex}
    \caption[Process flow classification of clinical outcomes]{\textit{Process flow classification of clinical outcomes}}
    \label{fig:process_flow_classification}
\end{figure}

\subsection{Mortality Classifier}

\noindent The statistical learning problem in this section is given by a two-class classification problem where mortality is the clinical outcome in question. Our objective is to see how well the algorithms mentioned in Figure (\ref{fig:ML_proc_thesis}) perform in predicting the probability of mortality. We will train the algorithms using $10$-fold cross validation and evaluate the results using the accuracy, i.e. the proportion of true results and the Cohen's kappa defined by:
\newpage
\begin{align}
    \kappa \equiv \frac{p_0 - p_e}{1 - p_e}
\end{align}
where $p_0$ is the accuracy given by ${\mathit  {ACC}}=({\mathit  {TP}}+{\mathit  {TN}})/(P+N)$, and $p_e = 1 / N^2 \sum_{k} n_{k1}n_{k2}$, where $k$ is the number of categories / classes, $N$ the number of items and $n_{k1}$ the number of times rater $i$ predicted category $k$. $p_e$ is also referred to as the expected accuracy, i.e. what the accuracy that any \textit{random} classifier would be expected to achieve. Accordingly, Cohen's kappa is also regarded as the inter-rater agreement for qualitative (categorical) items, i.e. it is similar to the classification accuracy, except that it is normalized at the baseline of random chance on a dataset. A possible interpretation of this    

\begin{figure}[h!]
    \centering
    \scalebox{.8}{\input{doc/thesis/images/classificationMortality.tex}}
    \caption[Binary classification results: mortality]{\textit{Binary classification results: mortality}}
    \label{fig:bi_class_mort}
\end{figure}

\newpage
\noindent statistics is given by the following \citep{ashby1991practical}: less than 0.20 = Poor agreement, 0.20 to 0.40 = Fair agreement, 0.40 to 0.60 = Moderate agreement, 0.60 to 0.80 = Good agreement and 0.80 to 1 = Very good agreement. As mentioned earlier, the statistical learning problem is that of a Binary classification problem given by whether  readmission / mortality occurred (\texttt{TRUE}) or not (\texttt{FALSE}), i.e. the expected accuracy is $p_e = 0.50$. The total number of patients with post-confirmed mortality in this data set is 115 (approx 36\% of the total number of patients, see table \ref{tab:outcomes_class}). The results of the mortality classification is illustrated in Figure (\ref{fig:bi_class_mort}) and Table (\ref{tab:class_mortality}). In the table we notice that there are three algorithm that overall yield very decent results given the accuracy and the kappa. These are in order of importance: the random forest (\texttt{rf}), logistic regression (\texttt{logr}) and linear discriminant analysis (\texttt{lda}). As we can see the random forest (\texttt{rf}) \citep{ho1995random} produces the best overall accuracy and kappa. The mean accuracy of the random forest classifier is estimated at 72\% with a kappa at 0.23. The next classifier which compared to random forest also yields decent results is the logistic regression (\texttt{logr}) with a mean accuracy of 67\% and a kappa of 12. The last algorithm is the linear discriminant analysis (\texttt{lda}). With the LDA the estimated prediction of the mortality in the HF patients is 67\% with a 

\input{doc/thesis/tables/classification_mortality.tex}
\newpage
\noindent kappa of 11. We need to emphasize that even though one gets a somewhat high accuracy, the kappa is often considered to be a more robust evaluation criteria compared to the accuracy. This is because it takes into account that the agreement between estimated classification and actual classification can occur by chance. As the kappa is very low for all the classifiers mentioned in table (\ref{tab:class_mortality}), we cannot say with certainty that the classification algorithms can systematically predict mortality. However, we have reasons to believe that the three algorithms (random forest, logistic regression and linear discriminant analysis) all show signs of being fair algorithms when it comes to predicting mortality in HF patients. This is not discouraging results as similar results are reported in the literature, see e.g. \cite{shah2014phenomapping} and \cite{panahiazar2015using}.

\subsection{Readmission Classifier}

\noindent In this section, we examine the classification problem related to readmission. We have defined the readmission outcome as whether a given patient was re-admitted in some form during the one-year period. As we mentioned in section (\ref{sec:data}) this could be either within 30 days (patient group \texttt{V}) or any other way (patient groups \texttt{U}). The results of the readmission classification is illustrated in Figure (\ref{fig:bi_class_read}) and Table (\ref{tab:class_readmission}). The results are very much different than what we found with the mortality classification. Surprisingly, three algorithms seem to distinguish themselves from the others, namely the random forest (\texttt{rf}), support vector machines (\texttt{svm}) and logistic regression (\texttt{logr}). Interestingly, all three of these algorithm score very high both in terms of accuracy and kappa. The algorithm with the most promising results is the random forest. It has an estimated mean prediction accuracy

\vspace*{-0,1cm}\input{doc/thesis/tables/classification_readmission.tex}

\noindent of 99.3\% with a kappa of 0.997. The random forest is found to be the most superior classification algorithm in both predicting mortality and readmission. This is not uncommon as in the literature there are many studies that report of the random forest being a very effective algorithm for classifying clinical outcomes, see e.g. \cite{austin2013using} and \cite{zolfaghar2013big}. The next algorithm that show potential in predicting readmission is the support vector machines (\texttt{svm}) algorithm. It also has an estimated mean accuracy of 99.3\% with a kappa of 0.997. We consider this to be interesting as in the previous section we found that the SVM was one of the lowest performing algorithms when it comes to predicting mortality. This might suggest that modelling re-admssion with a non-linear structure is more realistic than doing so with mortality. The last algorithm that show potential is that of the logistic regression (\texttt{logr}). The estimated mean accuracy for this algorithm was 97.5\% with a kappa of 0.989. In addition to having a very good accuracy and kappa, its worth mentioning that given is level of simplicity, one can argue that the logistic regression algorithm is more preferable to more advanced classification algorithm. In both the cases that we have examined, we have found that the random forest and the logistic regression algorithm perform decently. Both algorithms are also very different in terms of their level of complexity. They are also very much used in the literature and is often a favourite among practitioners of medical statistical analysis, see e.g. \cite{austin2013using}, \cite{zolfaghar2013big}, \cite{shah2014phenomapping} and \cite{panahiazar2015using}. Accordingly, we have reasons to believe that both the random forest and the logistic regression are the two main algorithms that show the most potential in predicting both the mortality and readmission of HF patients.

\begin{figure}[th!]
    \centering
    \scalebox{.8}{\input{doc/thesis/images/classificationReadmission.tex}}
    \caption[Binary classification results: readmission]{\textit{Binary classification results: readmission}}
    \label{fig:bi_class_read}
\end{figure}

\section{Discussion}

\noindent The objective of this thesis was two fold: (i) we attempted to give a though analysis of how well various clustering algorithms (hierarchical, k-means and expectation-Maximization) perform in producing phenotypically distinct clinical patient groups (i.e. phenomapping) with HFpEF and HFmrEF. Our strategy for answering this research question has been to compare the level of dissimilarity between patient groups that are produced at two levels. Firstly, we looked at the Bi-clustering problem where we compared the patient groups produced by the algorithms with that produced by the physicians. We found that if one defines the optimal clustering as that which has the highest number of significantly different baseline characteristics. Then we have reasons to believe that the hierarchical and k-means clustering algorithms show signs of being better at clustering patients with HF compared to the physicians. Overall these algorithms produce 62 significantly different baseline characteristics compared to 59 produced by the physicians. Secondly, we looked at how well the clustering algorithms performed in producing "new" patient groups within both subtypes of HF. We analyzed this by attempting to re-cluster patient groups from both subtypes (HFmrEF and HFpEF) produced by the physicians and the ML algorithms. Re-clustering within the subtypes generated by the physicians (also called the 'Post-diagnosis' assumption) seem to show the greatest potential as the average number of significantly different baseline characteristics is the highest for this clustering compared to when the assumption is removed. On average all algorithm produce approximately 53 (HFpEF) and 50 (HFmrEF) significantly different baseline characteristics when the post-diagnosis assumption is present compared to when its removed (46, HFpEF and 49, HFmrEF). However, if the objective is to use the results to find additional ''new clusters'', we cannot say with certainty that the choice of clustering algorithms or the clustering data used (whether its with or without post-diagnosis) will systematically enhance the "uniqueness" of the patient groups. We need to emphasize that the results need to be treated with great caution as they are very sensitive to the number of principal components used, the imputation method and the sample size. Nevertheless, the hierarchical and k-means algorithm seems to have the potential to be used as a tool by physicians to cross-check their assumptions and rational in order to further improve the diagnosis of patients with the preserved and mid-range subtypes of HF. Similar finding are also reported in the literature, see e.g. \cite{shah2014phenomapping}, \cite{ahmad2014clinical}, \cite{alonso2015exploring}, \cite{kao2015characterization}, \cite{ahmad2016clinical} and \cite{katz2017phenomapping}.\\
\indent In the second (ii) part of the thesis we attempted to evaluate the performance of various classification algorithms (k-nearest neighbour, linear discriminant analysis, support vector machines and random forest) in predicting mortality and readmission. The results seem to suggest that the random forest and logistic regression are good candidates for doing just that. They both rank very high compared to the other algorithms evaluated. The random forest has an estimated accuracy of approximately 72\% for mortality and 99.7\% for readmission. The logistic regression had similar results with approximately 67\% accuracy for mortality and 97.5\% for readmission. The results seem promising, but we need to emphasize that these results also need to be treated with great causation. As we mentioned in chapter (\ref{chap:method}), both the logistic regression and random forest have disadvantages. One of the strongest disadvantages for the logistic regression is the fact that one assumes a priori that the independent variables that are inputted into the algorithm are just that, i.e. independent among each other. This is a very strong assumption that we have not conducted a rigours examination of. This may in many ways affect the results. If the assumption of independence in not present then the model estimated may tend to overweight the significance of the observations that are not independent. The logistic regression also assumes little or no multicollinearity among the independent variables. This is also something that we have not tested in detail due to limitations. However, a way of testing this is thought the use of variance-inflation-factors (VIF) or other measures of multicollinearity severity. This may imply that that the results are susceptible to invalid inference and this is a major drawback to the results that we need to make the reader informed about. The random forest algorithm does not directly assume independence \citep{friedman2009elements}, but it assumes that the data is representative. As we mentioned in section (\ref{sec:data}), the data set used in this thesis had 15\% missing values. This is an aspect about our study that should not be neglected. We addressed the problem of missing values by imputation with a bootstrapped EM algorithm \citep{honaker2011amelia}. Maximum likelihood method such as this one is praised by many in the literature for its ability to impute missing values, even if the variables in question are mixed, see \cite{schafer1997analysis}, \cite{schafer1998multiple} and \cite{allison1999missing}. However, we cannot with certainty say that this the most optimal method of treating the missing values in the data set. Similarly to the clustering results, we need to emphasize that the results of the classification is sensitive to the choice of imputation method. Nevertheless, our findings seem to confirm a lot of the finding reported in the literature, see e.g. \cite{austin2012regression}, \cite{zolfaghar2013big}, \cite{shah2014phenomapping}, \cite{panahiazar2015using} and \cite{koulaouzidis2016telemonitoring}.\\
\indent For future analysis, we recommend broadening this study by evaluating more algorithms. This is especially the case for the clustering analysis. All the algorithms that we analyzed have an assumption of no noise, i.e. that all the patients belong to a cluster. This is a somewhat strong assumption as it could be the case that some patients lay in an area that is "too uncertain" to assign to either subtypes. It could be interesting to see how density-based algorithm such as DBSCAN \citep{ester1996density} would fair in producing phenotypically distinct patient groups. It could also be interesting to see how the classification results vary with the subtype of HF, i.e. is it reasonable to assume that some algorithm predict mortality and readmission more accurately if one is to limit the data to one subtype of HF? These are all suggestions for future analysis that can broaden our understanding of the complex syndrome that is heart failure. 

\end{document}