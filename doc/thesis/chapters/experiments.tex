\documentclass[../thesis.tex]{subfiles}

\begin{document}

\chapter{Experiments}
\label{chap:exp}

\noindent In this chapter, we present the results of the experiments done in this thesis. The results are split into two sections. The first section presents the results from the cluster analysis and the second section that of the classification of the clinical outcomes. For each of the sections we present an overview of the statistical learning problems that the algorithms are to solve. In this, we also present the assumptions and the evaluation criteria that are used to rank the algorithms given the statistical learning problem that they need to solve. 

\section{Cluster Analysis}

\noindent In the cluster analysis, we try to see how well the various clustering algorithms perform in producing phenotypically distinct clinical patient groups with HFpEF and HFmrEF. We organize this section in the following way: we start out by looking at the full sample data set, i.e. \texttt{HFfullDataSet.Rdat}. After the pre-processing, we will run the principal components thought the clustering algorithms. The idea is to see how well the clustering algorithms perform in producing patient groups that are more unique compared to the physicians evaluation. Our measure of success is the number of unique baseline characteristics that are statistically significant using the Person $\chi^2$ test for categorical variables, ANOVA for normally distributed variables and Kruskalâ€“Wallis test for non-normally distributed variables \citep{kruskal1952use}. Significance used is that of the conventional 5\% level. The implementation is done using the \texttt{multigrps}-function from the \texttt{CBCgrps}-package in \texttt{r} \citep{CBCgrps}. The algorithms are first going to be performed on the BI clustering HF problem, i.e. to see how unique the patient groups produced are given that the only HF subtypes in the dataset is HFmrEF and HFpEF. After this is completed, we will see how well the algorithms perform in producing new clusters within the already defined patient groups from the first round. We will do the same analysis on both the groups that have been defined by the physicians and the first round clustering results. The full process flow for the cluster analysis is illustrated in Figure (\ref{fig:process_flow_clustering}).

\begin{figure}
    \centering
    \input{doc/thesis/images/process_flow_clustering.tex}
    \caption[Process flow clustering of patient groups]{\textit{Process flow clustering of patient groups}}
    \label{fig:process_flow_clustering}
\end{figure}

\vspace*{-0,5cm}\subsection{The BI Clustering HF Problem}
\label{subsec:bi_clust}

In the current clustering problem we assume that the dataset is comprised of two clusters, i.e. HFmrEF and HFpEF. Accordingly, we allow the algorithms to determine the patients that best correspond to each group. We have plotted the results of the BI clustering problem in Figure (\ref{fig:bi_clust_results}). This plot can in many ways seem very misguiding as it only displays the results along the two first principal components. Still, as we can see from the table below, even if you only cluster based on the first four principal components (27.32\% of variance explained), one can produce more unique phenotypically distinct patient groups than the physicians. As we can see   

\input{doc/thesis/tables/baseline_char_actual_full.tex}

\input{doc/thesis/tables/baseline_char_HCKM_full.tex}

\noindent from table (\ref{tab:baseline_char_actual_full}), the  Hierarchical and K-Means clustering algorithms both give the highest number of significant baseline characteristics (7 for only the cont. variables in the table and 62 in total) compare with the actual clustering done by the physicians (4 for the cont. variables and 59 in total). The EM algorithm produces overall the lowest number of significant baseline characteristics (5 for cont. variables and 54 in total). Both the Hierarchical and K-Means algorithm produce the same clustering configurations. The baseline characteristics in the clustering of the patient using the Hierarchical and K-Means clustering show that for the first clustering (HFpEF) the \texttt{LVEF} are on average 57.5\% and for the second clustering (HFmrEF) the \texttt{LVEF} are on average 45\%. These are very similar values as that which was done by the physicians. We can also see for other baseline characteristics such as \texttt{ntprobnp} the average is at 2327 ng/L for the HFpEF group which is significantly different than that of the HFmrEF group 3723.5 ng/L, also this is very similar to what the physicians concluded with. For characteristics that are significantly different in the clustering with Hierarchical and K-Means clustering, but not done so for the physicians one can include the following continuous variables: hemoglobin (\texttt{hb}), packed cell volume (\texttt{pcv}) and the ewave (\texttt{ewave}). This may suggest that both the clustering algorithms can be used as appropriate tools for physicians. The results from the EM algo-

\input{doc/thesis/tables/baseline_char_EM_full.tex}

\noindent rithm (Table \ref{tab:baseline_char_actual_em}) show that a lot of the similar baseline characteristics are not statistically significant. The LVEF (\texttt{lvef}) and NTproBNP (\texttt{ntprobnp}) is very similar to both the Hierarchical and K-means clustering, but other characteristics such as hemoglobin (\texttt{hb}) and the packed cell volume (\texttt{pcv}) are not. Throughout the analysis we have found that the EM algorithm does not a good job of clustering patient groups compared to the Hierarchical and K-Means clustering algorithms. This could be because of the assumption of multivariate normal distribution does not hold for this data set.

\subsection{Analysis of Post-Diagnosis}

\noindent In this section we will investigate the clustering results discussed previously. We will place an assumption of weather the physicians diagnosis is representative given an objective of producing the most unique patient groups. The clustering problem in this section assumes that the diagnosis done by the physicians is sufficient in regards to this objective, i.e. the clustering based on the \textit{post-diagnosis} done by the physicians produces the most unique patient groups. We will compare these results to a clustering without an assumption of post-diagnosis done by the physicians and see if 

\input{doc/thesis/tables/results_clustering_subtypes.tex}

\noindent there are any substantial differences in results. We will only use the first two principal components (14.64\% of variance explained) to cluster the patients. The evaluation criteria is the same as in the previous section. We can see from table (\ref{tab:n_baseline}) that the Hierarchical and K-Means clustering algorithms almost always produce the same number of significant baseline characteristics. The only exception seems to be were one does not assume a post-diagnosis of the HFmrEF subgroup. The overall algorithm that produces the lowest number of significant baseline characteristics is the Expectation maximization algorithm. Starting with the algorithms performance given the assumption of post-diagnosis. We can see from table (\ref{tab:baseline_char_phy_p_hc}) and (\ref{tab:baseline_char_phy_p_km}) that for the case with HFpEF, cluster 2 seems to contain patients that have a higher average \texttt{age} (85.45) with a packed cell volume (\texttt{pcv}) that is on average 0.33 $\pm$ 0.05. Given this information this puts cluster 2 right in the middle of clusters 1 and 3. The ntprobnp (\texttt{ntprobnp}) of cluster 3 is the lowest at 1417 ng/L which is also statistically significant. The average number of red blood cells, i.e. the mean corpusular volume (\texttt{mcv}) is on average 87 femtolitres which is less than clusters 2 and 3. Overall, we have 8 continuous significantly different baseline characteristics with 47 being categorical (each significant category is counted independently). The EM algorithm produced almost similar results for the subgroup HFpEF (table \ref{tab:baseline_char_phy_p_em}). The second cluster produced by the EM algorithm is very similar to the first cluster produced by the Hierarchical and K-Means algorithm. The ntprobnp (\texttt{ntprobnp}) for cluster one and two produced by the EM are very similar. Both are approximately 2750 ng/L. The third cluster has the lowest values for the ntprobnp (1525 nl/L). Accordingly, we can see that cluster 3 produced by the EM algorithm is very similar to the third cluster produce by the Hierarchical and K-Means algorithms. The total number of significant baseline characteristics for the EM algorithm is 53 (8 cont. and 45 categorical). When looking at the HFmrEF clustering based on post-diagnosis, we can see that a somewhat different results shows up, i.e. there are less significantly different baseline characteristics. For cluster 3, we see that the lowest ntprobnp (\texttt{ntprobnp}) at 2898.5 ng/L with a packed cell volume of 0.38 $\pm$ 0.04. This cluster also contains the patients with the lowest length of stay (7 days). The length of stay (\texttt{LOS}) is also a uniquely statistical significant baseline characteristic that is only significant in the HFmrEF subgroup of patients. This cluster also has the highest hemoglobin (\texttt{hb}) at 23.79 $\pm$ 12.89 g/100mL. Comparing the number of significant baseline characteristics between the HFmrEF groups both with and without the post-diagnosis assumption one can see that the latter has fewer in the case with the assumption, see table (\ref{tab:n_baseline}). The same goes for the HFpEF group, i.e. we have reasons to believe that assuming the physicians diagnosis is representative one can get additional clustered patient groups with higher degree of homogeneity compared to when this assumption is not intact. We have also demonstrated that the ML algorithms can be very useful in producing patient groups that are more phenotypically unique given that the objective is to challenge the diagnosis of the physicians, see section (\ref{subsec:bi_clust}). Now that we have presented the results of the clustering analysis, we move on to the results of the classification of the clinical outcomes. The source code, relevant plots and tables can be found in the appendix (\ref{chap:data_desc}).

\section{Classification}

\noindent In this section we will present the results of the classification analysis. As mentioned in ML the procedure (figure \ref{fig:ML_proc_thesis}), we run the imputed data set through the various classification algorithms and accordingly run a cross validation in order to estimate the accuracy of the various algorithms. The accuracy along with Cohenâ€™s kappa are the two evaluation criteria we use to rank the algorithms in this section. The process flow for the mentioned classification section is illustrated in Figure (\ref{fig:process_flow_classification}). 

\begin{figure}
    \centering
    \input{doc/thesis/images/process_flow_classification.tex}
    \caption[Process flow classification of clinical outcomes]{\textit{Process flow classification of clinical outcomes}}
    \label{fig:process_flow_classification}
\end{figure}

\subsection{Mortality Classifier}

\noindent The statistical learning problem in this section is given by a two-class classification problem where mortality is the clinical outcome in question. Our objective is to see how well the algorithms mentioned in Figure (\ref{fig:ML_proc_thesis}) perform in predicting the probability of mortality. We will train the algorithms using $5$-fold cross validation and evaluate the results using the accuracy, i.e. the proportion of true results and the Cohen's kappa defined by:
\begin{align}
    \kappa \equiv \frac{p_0 - p_e}{1 - p_e}
\end{align}
where $p_0$ is the accuracy given by ${\mathit  {ACC}}=({\mathit  {TP}}+{\mathit  {TN}})/(P+N)$, and $p_e = 1 / N^2 \sum_{k} n_{k1}n_{k2}$, where $k$ is the number of categories / classes, $N$ the number of items and $n_{k1}$ the number of times rater $i$ predicted category $k$. $p_e$ is also referred to as the expected accuracy, i.e. what the accuracy that any \textit{random} classifier would be expected to achieve. Accordingly, Cohen's kappa is also regarded as the inter-rater agreement for qualitative (categorical) items, i.e. it is like classification accuracy, except that it is normalized at the baseline of random chance on a dataset. A possible interpretation of this statistics is given in by the following \citep{ashby1991practical}: less than 0.20 = Poor agreement, 0.20 to 0.40 = Fair agreement, 0.40 to 0.60 = Moderate agreement, 0.60 to 0.80 = Good agreement and 0.80 to 1 = Very good agreement. As mentioned earlier, the statistical learning problem is that of a Binary classification problem given by weather re-admission / mortality occurred (\texttt{TRUE}) or not (\texttt{FALSE}), i.e. the expected accuracy is $p_e = 0.50$. The total number of patients with post-confirmed mortality in this data set is 115 (approx 36\% of the total number of patients, see table \ref{tab:outcomes_class}). In addition to the classification algorithms mentioned in Figure (\ref{fig:ML_proc_thesis}), we have also included an additional set of algorithms (Naive Baise \texttt{nb} and logistic regression \texttt{logr}) for further analysis. These algorithms were not discussed in further details in the pre- 
\begin{figure}[h!]
    \centering
    \scalebox{.8}{\input{doc/thesis/images/classification_mortality.tex}}
    \caption[Bi-classification of mortality as clinical outcome]{\textit{Bi-classification of mortality as clinical outcome}}
    \label{fig:bi_class_mort}
\end{figure}

\noindent vious chapter, but are very common in the literature. The results of the mortality classification is illustrated in Figure (\ref{fig:bi_class_mort}) and Table (\ref{tab:class_mortality}). In the table we notice that there are three algorithm that overall yield very decent results given the accuracy and the kappa. These are in order of importance: the random forest (\texttt{rf}), linear discriminant analysis (\texttt{lda}) and logistic regression (\texttt{logr}). As we can see the random forest (\texttt{rf}) \citep{ho1995random} produces the best overall accuracy and kappa. The mean accuracy of the random forest classifier is estimated at 72\% with a kappa at 23. The next classifier which compared to random forest also yields decent results is the linear discriminant analysis (\texttt{lda}). With the LDA the estimated prediction of the mortality in the HF patients is 66\% with a kappa of 14. The last algorithm is the logistic regression (\texttt{logr}) with a mean accuracy of 65\% and a kappa of 11. We need to emphasize that even though one gets a somewhat high accuracy, the kappa is often considered to be a more robust  

\input{doc/thesis/tables/classification_mortality.tex}

\noindent evaluation criteria compared to the accuracy. This is because it takes into account that the agreement between estimated classification and actual classification can occur by chance. As the kappa is very low for all the classifiers mentioned in table (\ref{tab:class_mortality}), we cannot say with certainty that the classification algorithms can systematically predict the mortality outcome. However, we have reasons to believe that the three algorithms (random forest, linear discriminant analysis and logistic regression) all show signs of being fair algorithms when it comes to predicting mortality in HF patients. This is not discouraging results as similar results are reported in the literature, see e.g. \cite{shah2014phenomapping} and \cite{panahiazar2015using}.

\subsection{Re-admission Classifier}

\noindent In this section, we examine the classification problem related to re-admission. We have defined the re-admission outcome as whether a given patient was re-admitted in some form during the one-year period. As we mentioned in section (\ref{sec:data}) this could be either within 30 days (patient group \texttt{V}) or any other way (patient groups \texttt{U}). The results of the re-admission classification 

\begin{figure}[h!]
    \centering
    \scalebox{.8}{\input{doc/thesis/images/classification_readmission.tex}}
    \caption[Bi-classification of re-admission as clinical outcome]{\textit{Bi-classification of re-admission as clinical outcome}}
    \label{fig:bi_class_read}
\end{figure}

\noindent are illustrated in Figure (\ref{fig:bi_class_read}) and Table (\ref{tab:class_readmission}). The results are very much different than what we found with the mortality classification. Surprisingly, three algorithms seem to distinguish themselves from the others, namely the random forest (\texttt{rf}), support vector machines (\texttt{svm}) and logistic regression (\texttt{logr}). Interestingly, all three of these algorithm score very high both in terms of accuracy and kappa. The algorithm with the most promising results is the random forest. It has an estimated mean prediction accuracy of 99.7\% with a kappa of 0.994. The random forest is found to be the most superior classification algorithm in both predicting mortality and re-admission. This is not uncommon as in the literature there are many studies that report of the random forest as being a very effective algorithm for classifying clinical outcomes, see e.g. \cite{austin2013using} and \cite{zolfaghar2013big}. The next algorithm that show potential in predicting re-admission is the support vector machines (\texttt{svm}) algorithm. It has an estimated mean accuracy of 99.5\% with a kappa of 0.987. We consider this to be interesting as in the previous section we found that the SVM was one of the lowest performing algorithms when it comes to predicting mortality. The last algorithm that show potential is that of the logistic regression (\texttt{logr}). The estimated mean accuracy for this algorithm was 99.2\% with a kappa of 0.981. In addition to having a very good accuracy and kappa, its worth mentioning that given is level of simplicity, one can argue that the  

\input{doc/thesis/tables/classification_readmission.tex}

\noindent logistic regression algorithm is more preferable to more advanced classification algorithm. In both the cases that we have examined, we have found that the random forest and the logistic regression algorithm perform decently. Both algorithms are also very different in terms of their level of complexity. They are also very much used in the literature and is often a favourite among practitioners of medical statistical analysis, see e.g. \cite{austin2013using}, \cite{zolfaghar2013big}, \cite{shah2014phenomapping} and \cite{panahiazar2015using}. Accordingly, we have reasons to believe that both the random forest and the logistic regression are the two main algorithms that show the most potential in predicting both the mortality and re-admission of HF patients.



\section{Discussion}

\end{document}