\documentclass[../thesis.tex]{subfiles}
\begin{document}

\chapter{Background}
\label{chap:back}

The following chapter presents a thorough treatment on the literature of the application of ML techniques for the assessment of heart failure\footnote{We highly recommend reading \cite{tripoliti2017heart} for a broader overview of the literature on the state-of-the-art ML techniques applied for the assessment of heart failure.}. Important topics such as HF detection, subtype estimation and prediction of clinical outcomes in the context of ML will be presented and explained.

\section{HF detection}
\label{sec:hfdet}

\noindent The ESC defines HF as a clinical syndrome caused by structural and/or functional cardiac abnormality, resulting in a reduced cardiac output (CO) and/or elevated intracardiac pressures at rest or during stress. It is typically characterized by symptoms, such as breathlessness, ankle swelling and fatigue that may be accompanied by signs, such as elevated jugular venous pressure (JVP), pulmonary crackles and peripheral oedema (swelling in lower limbs) \citep{ponikowski2016}. HF prevents the heart from fulfilling the circulatory demands from the body, due to its impairing abilities on the ventricles to maintain the bodies hemodynamics (blood flow). As there is no broad definitive industry accepted diagnostic test for HF, one finds in clinical practice that medical diagnosis is done with a combination of careful examinations (physical and historical) with assisting tests, such as blood tests, chest radiography (chest X-ray, CXR), electrocardiography (EKG) and echocardiography (cardiac echo), see e.g \cite{henein2010heart} and \cite{son2012decision}. As a result of this, several criteria for determining the presence of HF have been proposed, including the Framingham criteria \citep{mckee1971natural}, the Boston criteria \citep{carlson1985analysis}, the Gothenburg criteria \citep{eriksson1987cardiac} and the ESC criteria \citep{swedberg2005guidelines} \citep{roger2010heart}. All of which are much used.\\
\indent In a non-acute onset, the ESC has also defined an algorithm for diagnosing HF \citep{ponikowski2016}. The algorithm is structured in the following way: The probability of HF ($\hat{p}_{HF}$) is evaluated along three dimensions: 
\begin{enumerate}[label=(\roman*)]
    \item \textbf{Prior clinical history}: History of coronary artery disease (CAD) or arterial hypertension, exposition to cardiotoxic drugs/ radiation, diuretic use (any substance that promotes the production of urine) or orthopnea (shortness of breath when lying down)
    \item \textbf{Physical examination}: Crackles/rales, bilateral ankle oedema (swelling in both ankles), abnormal heart sounds/murmur, jugular venous dilatation, laterally displaced/broadened apical beat (pulse felt at the point of maximum impulse (PMI))
    \item \textbf{Abnormalities in electrocardiography (EKG)}
\end{enumerate}
\indent If all elements along the three dimensions are normal/absent, $\hat{p}_{HF}$ is estimated to be highly unlikely. Should, however, at least one element be abnormal, then plasma Natriuretic Peptides (NP)\footnote{A hormone, mainly secreted from the heart, that has important natriuretic and kaliuretic properties (excretion of sodium and potassium in the urine) \citep{pandit2011natriuretic}. In clinical practice it is found that brain NP (also called BNP) levels can be used to predict the risk of death and cardiovascular events  \citep{wang2004plasma}.} should be measured in order to identify patients who need echocardiography. Specifically, should the NP values be above the exclusion threshold\footnote{The recommended threshold levels are BNP levels $\geq 35 pg/mL$ or NTproBNP levels $\geq 125 pg/mL$, see e.g. \cite{cowie1997value}, \cite{yamamoto2000clinical}, \cite{krishnaswamy2001utility}, \cite{zaphiriou2005diagnostic}, \cite{fuat2006diagnostic} and \cite{maisel2008state}.} or should the assessment of NPs not be routinely done in clinical practice then patients need to be forwarded for an echocardiography. With the help of the cardiac echo, specialist can detect abnormalities in the heart rhythm. Should the results of the plasma NP or the echocardiography be normal\footnote{Normal ventricular and atrial volumes and function \citep{aune2009normal}.}, then HF is also considered unlikely. \input{doc/thesis/images/ESC_algo_HF.tex} Should the results of the echo yield any abnormal results, appropriate HF treatment should be initiated. The structure of the ESC algorithm is shown as a flow chart in figure (\ref{fig:esc_algo_hf}). Being that the ESC algorithm is much used in clinical practice throughout the world, there is research that suggest that the medical and economic benefits of applying ML in the detection of HF should not be ignored. In the context of diagnosing patients with HF, the benefits typically include (i) less time consumption, (ii) more support (large global community of ML practitioners in business and academia) and (iii) same level of accuracy as conventional tools when applied on available data. Many ML methods used to detect HF as a statistical learning problem, fall in the category of \textit{supervised} statistical learning (see section \ref{subsec:supervisedlearn}). The relevant ones include expressing the detection of HF as a two class classification problem, where the presence of HF is the output of the classifiers. Methods including logistic regression, linear discriminant analysis (LDA), Bayesian classifier, k-nearest neighbours (k-NN), random forests (RF), boosting, support vector machines (SVM) and neural networks (NN) are all very popular. As the response variable of the classification problem is categorical, most ML studies tend to use measures of heart rate variability (HRV)\footnote{HRV is the amount of heart rate fluctuations around the mean heart rate \citep{van1993heart}. The HRV can be assessed using R-waves produced by an EKG and reduced HRV is typically an established sign of HF \citep{ernst2016heart}.} as the main predictors for distinguishing patients as normal or with HF \citep{tripoliti2017heart}. Other predictors include parameters from clinical tests (i.e. blood test, echo, EKG, chest radiography), clinical variables (e.g. gender, age, blood pressure, smoking habit) and other lab-

\input{doc/thesis/tables/ML_HF_detection.tex}

\noindent oratory findings. Relevant articles where one applies ML techniques to address the statistical learning problem of detecting patients with HF is shown in table (\ref{tab:ML_HF_detection_lit}). Some common evaluation measures used in such research include: sensitivity (true positive rate), specificity (true negative rate) and accuracy\footnote{The fraction/proportion of true positives (\textit{sensitivity}) or true negatives (\textit{specificity}) correctly identified \citep{james2013introduction}.}. The accuracy is the only evaluation measure reported in table (\ref{tab:ML_HF_detection_lit}). We also need to emphasize that as this particular statistical learning problem (i.e. detection of HF) is one that falls outside of the scope of the problem statement mentioned in chapter (\ref{chap:intro}). We will not be pursuing a further literature review of this problem. However, we highly recommend reading the likes of \cite{tripoliti2017heart}, \cite{acharya2017application} or \cite{awan2018machine}, for a more up-to-date overview of the literature on ML used for HF detection. 


\section{Subtype Estimation}
\label{sec:subtypeest}

\noindent According to the ESC algorithm (figure \ref{fig:esc_algo_hf}), once HF is confirmed and the probability of HF is assessed and estimated to be likely, the next step is to estimate the causes (aetiology) or subtypes of HF. The main definition of HF subtypes is based on historical research. Most of the research done after the 1990s emphasizes estimating the subtype of HF patients based on the measure of the left ventricle ejection fraction (LVEF). The two usual ways of obtaining the LVEF values are through an echocardiography or cardiac magnetic resonance imaging (CMR or cardiac MR) \citep{ponikowski2016}. In prior guidelines presented by the ESC, HFrEV and HFpEF were the two main subtypes of HF \citep{authors2012esc}. The ESC did however acknowledge that a gray zone existed between the two. As a result of this a new subtype was introduced, namely HFmrEF. The ESC did so in hopes of stimulating research into the underlying characteristics, pathophysiology and treatment of this group of patients \citep{ponikowski2016}. Details about the criteria for the various HF subtypes are shown in table (\ref{tab:HF_subtypes}). The differences between HFmrEF and HFpEF are difficult to distinguish. As mentioned earlier, these two groups were previously only classified as HFpEF. Diagnosing HFpEF is a very complex process with the diagnosis of chronic HEpEF being especially cumbersome in elderly patients with one or more additional diseases (comorbidity). With the exception of the LVEF 

\input{doc/thesis/tables/HF_subtypes.tex}

\noindent values, signs and symptoms between HFmrEF and HFpEF are often non-specific and do not discriminate between other clinical conditions. LVEF $\geq$ 50\% is also considered to be normal. The ECS has also underlined the difficulties with an emphasis on the LVEF as the main discriminant between HFmrEF and HFpEF. The cut-off at 50\% is set arbitrary and in clinical trials patients with LVEF between 40\% and 49\% are often classified as HFpEF, see e.g. \cite{kelly2015patient} and \cite{ponikowski2016}. The ESC places an emphasis on additional objective measures of cardiac dysfunction in order to sufficiently discriminate the two subtypes, but currently no gold standard exists. The hope of stimulating more research into the characteristics of the patient group HFmrEF has fuelled much research into the application of ML, to further advance the literature. The appeal from the ESC into further research has also served as a motivation for much of the research done.  Accordingly, we have organized the literature review of the "state-of-the-art" research into two parts and have structured the literature based on the statistical learning problem category, i.e. supervised or unsupervised.

\subsection{Supervised Learning}
\label{subsec:supervisedlearn}

\noindent In this thesis we use the terms \textit{machine learning} (ML) and \textit{statistical learning} (SL) interchangeably. Even though the two are very closely linked, they do differ in terms of emphasis and terminology. ML is defined as \textit{"a set of methods that can automatically detect patterns in data, and then use the uncovered patterns to predict future data, or to perform other kinds of decision making under uncertainty"} \citep{muphy2012machine}. SL on the other hand is often considered to be the statistical framework of ML, and emphasize the importance of building \textit{probabilistic} models for the analysis and prediction of data in order to draw inference, see e.g. \cite{friedman2009elements}, \cite{muphy2012machine}, \cite{james2013introduction} and \cite{wasserman2013all}. Individuals of both camps (i.e. computer scientists and statisticians) often use different language for the same thing. In this thesis we refer to the underlying learning problem to be solved by a given algorithm as a statistical learning problem. The actual algorithms used to solve the SL problem are referred to as ML methods/algorithms\footnote{We need to emphasize that the methods can also be called statistical learning methods/algorithms as they are often done so in the literature.}. This is done to hopefully reduce confusion for the readers.\\
\indent Most SL problems fall into one of two main categories, i.e. \textit{supervised} and \textit{unsupervised} learning, see e.g. \cite{friedman2009elements} and \cite{james2013introduction}\footnote{The categories are also referred to as the two main types of ML, see e.g. \cite{muphy2012machine}}. The example of detecting  HF we discussed in section (\ref{sec:hfdet}) is typically a learning problem that falls into the supervised learning domain. For each predictor(s) (input(s) or independent variable(s)) $x_i$, $i= 1,\hdots,n$ there is an associated response (output or dependent variable), $y_i$. The objective of supervised learning is to fit a model that relates the response ($y_i$) to the predictors ($x_i$) \citep{james2013introduction}. Supervised learning is the most common category of SL problem in practice. Of the ML methods most used to solve supervised SL problems, one typically mentions \textit{classification}. The goal of classification is to learn a mapping from the predictors ($x_i$) to the response ($y_i$), where $y \in \{ 1, \hdots, C\}$, with $C$ being the number of classes. We can formalize classification as a SL problem by referring it to as a functional approximation problem. We assume a functional form $y = f(\mathbf{x})$ exists for some unknown function $f$, and the goal of the learning process is to estimate $f$ given a training set with labeled and known values. We can then use the estimated function $\hat{y} = \hat{f} (\mathbf{x})$ to make predictions on a testing / validation set \citep{muphy2012machine}.\\
\indent The application of classification to estimate HF subtypes is a relatively new approach. HF subtype estimation using ML in earlier research have similarities with HF detection. Both subjects reduce the classification problem to a two class classification problem with the assumption that the predicted responses are mutually exclusive. As $C = 2$, one often call this a \textit{binary classification} problem. In which case one often assumes that $y \in \{0,1\}$ \citep{muphy2012machine}. Prior to the ESC introduction of HFmrEF as a third subtype of HF, most ML research focused on classifying HF patients according to the two common subtypes, i.e. HFrEF and HFpEF. A list of some relevant literature can be found in table (\ref{tab:ML_HF_subtype_supervised_lit}). Most predictors have features including measures of demographic characteristics, HRV, signs and symptoms, vital signs, results of laboratory investigations and previous medical history. Methods include bagging, boosting, random forest, supp-

\input{doc/thesis/tables/HF_subtypes_supervised.tex}

\noindent ort vector machines (SVM), Naive-Bayes, nearest neighbour classifiers (NNC), k-nearest neighbours (k-NN) and neural networks (NN). As classification methods are much used in the literature of HF subtype estimation, we reserve the use of these methods in a later section dealing with the prediction of clinical outcomes (see section \ref{sec:predclincout}). Supervised learning methods also assume a priori that there exists a response $y_i$ with a predefined number of classes ($C$). Because of this we feel that such an application to the problem of HF subtype estimation would fall outside the scope of the problem statement mentioned in chapter (\ref{chap:intro}). One of the main motivations of this thesis is to investigate how well it is possible to produce phenotypically distinct clinical patient groups using dense phentoypic data (also known as phenomapping). Given the motivation, we seek to better understand a possible relationship between patient groups by placing an assumption of no response variable to supervise our analysis. To answer this question, we turn to the second main category of SL problems, namely unsupervised learning.


\subsection{Unsupervised Learning}
\label{subsec:unsupervisedlearn}

\noindent The main goal of unsupervised learning is to discover hidden structures in the data that are not predefined. Sometimes its also refereed to as \textit{knowledge discovery} and is widely used, as it is arguably more typical for animal and human learning. The formalization of unsupervised learning is often done in the setting of \textit{unconditional density estimation}, i.e. we want to build models of the form $p(\mathbf{x}_i | \theta)$. Instead of a conditional setting as done with supervised learning, i.e. $p(y_i | \mathbf{x}_i, \theta)$, the use of unsupervised learning is often considered to be more "convenient" than supervised learning, as it does not require an expert to manually label all the data \citep{muphy2012machine}. This convenience is often stated as a major reason for the relevance of unsupervised learning done for distinguishing phenotypical characteristics between HF patient groups. Not to mention that there is no agree-upon measure of what distinguishes HF subtypes (see section \ref{sec:subtypeest}). Furthermore, because of the complex nature and high degree of heterogeneity of HF subtypes such as HFpEF, the sole use of genetic information for helping to \textit{precisely} classify HF subtypes has often been seen as unlikely. Uncertain behavior by weak genetic factors is very probable in eliciting disease phenotypes \citep{deo2015machine}. This additional complexity is avoided by framing the SL problem in the setting of unsupervised learning.\\
\indent A lot of research has been conducted using unsupervised learning to group HF patients into subtypes with phenotypically distinct characteristics. Of the ML methods most used here, one typically finds \textit{clustering} methods. These methods are designed to find subgroups or \textit{clusters} within a data set. The goal of clustering is to partition the data set into distinct groups with high degree of homogeneity and arranging the clusters into a natural hierarchy \citep{friedman2009elements}. A list of the newest literature on the application of clustering methods for phenomapping of HF patients is shown in table (\ref{tab:ML_HF_subtype_unsupervised_lit}). Of the clustering methods found here, one can men-

\input{doc/thesis/tables/HF_subtypes_unsupervised.tex}

\noindent tion hierarchical, K-Means, model-based clustering, such as expectation maximization (EM), sequential information bottleneck algorithm (SIBA) and latent class analysis (LCA). Addressing phenomapping within an unsupervised setting was started with \cite{ahmad2014clinical} and \cite{shah2014phenomapping}. The latter employed the use of hierarchical and penalizing model-based clustering to distinguish HFpEF patients. The analysis was done on 67 continuous variables including clinical, laboratory, electrocardiography and echocardiography features. The results suggest that HFpEF patients can be clustered into three distinct pheno-groups with meaningful, clinically relevant categories.\\
\indent \cite{ahmad2014clinical} did a similar analysis using 45 baseline clinical variables on a much larger data set consisting of 1619 patients with chronic HF (i.e. both HFrEF and HFpEF). The study identified four clusters of patients which varied considerably along measures of demographics, symptoms and comorbidities. The study underscored the high degree of disease heterogeneity that exists within chronic HF patients and the need for improved phenotyping of the syndrome. \cite{alonso2015exploring} used a somewhat different approach to phenomapping HF patient groups. Their objective was to use ML techniques to discriminate between patients with preserved EF and those with reduced EF using the concept of the Volume Regulation Graph (VRG)\footnote{A graph of ESV versus EDV, which has the clear advantage of yielding (nearly perfect) linear relationships \citep{beringer1998unifying}.}. The authors evaluated three clustering methods (i.e. K-Means, EM and SIBA) and found that the algorithms generated dividing patterns. \cite{kao2015characterization} used latent class analysis (LCA) on a data set of 4113 HFpEF patients along 11 prospectively selected clinical features. The use of LCA is in many ways different than other clustering algorithms as it does not require continuous variables. It is optimized for analyzing categorical variables and identifies clusters based several traits rather than a single trait. With the use of LCA the authors identified 6 subgroups of HFpEF patients with significant differences in event-free survival. Other authors like \cite{katz2017phenomapping} and \cite{ahmad2016clinical} have organized their research along different phenomapping objectives. The latter addressed phenomapping on patients diagnosed with acute decompensated heart failure (ADHF), and \cite{katz2017phenomapping} on the systemic hypertensive patients with myocardial substrate (i.e. abnormal cardiac mechanics). As the two studies have a different phenomapping objective than the ones mentioned earlier, they still managed to identify four and two respective patient groups with acute ADHF and systemic hypertension with myocardial substrate.\\
\indent The number of studies done on phenomapping HF patients is eminence and as evident from table (\ref{tab:ML_HF_subtype_unsupervised_lit}), the results vary considerably with respect to the optimal number of clusters. This is something that this thesis will try to address by re-evaluating a number of the clustering methods used in the literature, but along a single phenomapping objective. Before that time, we move on to reviewing the literature associated with the second objective of the problem statement, namely predicting clinical outcomes due to HF.

\section{Prediction of Clinical Outcomes}
\label{sec:predclincout}

\noindent As we mentioned in chapter (\ref{chap:intro}), HF is a syndrome that globally effects approximately 65 million people \citep{hay2017global}. In addition to the high prevalence and overall reduced quality of life (QoL), one cannot but mention the many serious clinical outcomes. This includes, but is not limited to mortality, morbidity, destabilization and readmission. These outcomes effect not only the patients and their families, but also the society. The patients and their families are effected by the many constraints that HF places on family life and an overall reduction in QoL. With the emotional dimensions of health being more important than the physical dimensions \citep{dunderdale2005quality}, the society is effected by the many economic constraints, such as an increase in the burden and cost of national health care expenditures. With the main driver of costs related to HF being that of hospitalization, where about 60-70\% of HF costs are related to inpatient case and almost 20\% to primary care \citep{braunwald2015war}. The use of prognostics can assist in the monitoring and treatment of HF patients, with the goal of improving the quality of care and the outcomes of patients hospitalized with HF 
\citep{tripoliti2017heart}.\\
\indent Conducting good prognostics is often conditional on estimating the severity of HF of a given patient. Accordingly, the two most used classification systems for the severity estimation, is the New York Heart Association (NYHA) Functional Classification \citep{new1994nomenclature} and the American College of Cardiology/American Heart Association (ACC/AHA) stages of HF \citep{hunt2001acc}. The NYHA system places the patients in one of four categories based on how much they are limited during physical activity and is based on symptoms as well as physical activity. The ACC/AHA system on the other hand structures HF stages based on structural changes to the heart and symptoms. Both systems provide complementary information about the presence and severity of HF. The various stages and classes of the two systems are shown in figure (\ref{fig:HF_severity_systems}). Being that the NYHA classification system is based on subjective evaluation, it has been criticized because of a lack of taking into account the variability that can occur within patient groups. Furthermore, with the ACC/AHA system there is no moving backwards to prior stages, i.e. ones a patient is assigned a HF stage. The patient can never again achieve a different prior stage. With the NYHA it's different as patients can move between classes relatively quickly, as these are all based on symptoms alone, see \cite{fleg2000assessment} and \cite{yancy2013}. Most studies address HF severity estimation by expressing the statistical learning problem as a two or three class classification problem. The use of ML to address this particular SL problem will not be pursued, as the focus will be on the second objective of the problem statement, namely the prediction of clinical outcomes. The use of severity estimation is very important as it serves as complementary information for medical practitioners to give objective prognostics about HF patients.\input{doc/thesis/images/HF_serverity_systems.tex} A lot of studies have been conducted on the use ML to estimate HF severity, and again we recommend reading \cite{tripoliti2017heart} for a further overview of the literature. As for the prediction of clinical outcomes it's especially readmission and mortality that has gained a lot of interest by researchers. readmission is important because of the negative impact on healtcare systems' budgets. Mortality is obviously important as HF is one of the leading causes of death worldwide. The use of prediction models for mortality can benefit both physicians and patients. The literature is full of models taking into account various factors in producing statistical models that have the objective of predicting mortality. Some of the most used statistical methods include the Kaplan-Meier estimator \citep{kaplan1958nonparametric} and multiple variable Cox proportional hazard models \citep{cox1972regression}. All of which have lead to the formation of multiple scores that estimate the risk of mortality that are much used in clinical practice. Examples include: the Enhanced Feedback for Effective Cardiac Treatment (EFFECT) Score \citep{lee2003predicting}, Seattle Heart Failure Model \citep{levy2006seattle}, Get With the Guidelines (GWTG) Score \citep{peterson2010validated} and Heart Failure Survival Score \citep{ketchum2011multivariate}. A small list of the relevant literature related to the application

\input{doc/thesis/tables/HF_prediction_clinical_outcomes.tex}

\noindent of ML for predicting readmission and mortality is shown in table (\ref{tab:ML_HF_predition_outcomes}). One of the first to use ML methods for this particular SL problem was \cite{austin2012regression}. They investigated predicting the 30-day mortality using a binary variable to denote whether a patient died within 30 days of hospital admission. Methods used include: Logistic regression and trees, Bagged, Boosted trees and Random forest. The researchers used the methods on a total of 8240 baseline patients and 7608 follow-ups. The results seemed to suggest that Logistic Regression and Boosted Regression trees are the most accurate with area under the curve (AUC) of 0.786 and 0.777 respectively. \cite{zolfaghar2013big} applied logistic regression and random forest to predict 30 day risk of readmission. This was done on a data set consisting of 1.681.562 patients. The predictors of the analysis contained more than 100 features. The accuracy was 78.03\% and 87.12\%, with 70\% of the data set being reserved for training and 30\% for testing. \cite{shah2014phenomapping} analyzed the prediction of both readmission and mortality on 397 patients and 67 clinical variables using support vector machines (SVM). The precision of mortality and readmission were 60.90\% and 63.60\%. As is evident from table (\ref{tab:ML_HF_predition_outcomes}), the accuracy and precision of the prediction models using ML methods varies throughout the various studies. Along with the variability in the number of optimal clusters mentioned in section (\ref{subsec:unsupervisedlearn}), we'll also try to address this point by again re-evaluating the performance of a number of classification algorithm related to the SL problem of predicting clinical outcomes. 

\end{document}